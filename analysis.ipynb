{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>departamento</th>\n",
       "      <th>municipio</th>\n",
       "      <th>sexo</th>\n",
       "      <th>a単o_registrado</th>\n",
       "      <th>edad</th>\n",
       "      <th>periodo</th>\n",
       "      <th>etnia</th>\n",
       "      <th>escolaridad</th>\n",
       "      <th>ocupacion</th>\n",
       "      <th>causa</th>\n",
       "      <th>asistencia</th>\n",
       "      <th>lugar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.0</td>\n",
       "      <td>1703</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>28</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M329</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0101</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>88</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E142</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0101</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>74</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E039</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0101</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>43</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E149</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0101</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>88</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E119</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  departamento municipio sexo a単o_registrado  edad periodo etnia escolaridad  \\\n",
       "0         17.0      1703  1.0           2012    28     3.0   NaN         1.0   \n",
       "1          1.0      0101  2.0           2012    88     3.0   NaN         2.0   \n",
       "2          1.0      0101  2.0           2012    74     3.0   NaN         2.0   \n",
       "3          1.0      0101  2.0           2012    43     3.0   NaN         2.0   \n",
       "4          1.0      0101  2.0           2012    88     3.0   NaN         2.0   \n",
       "\n",
       "  ocupacion causa asistencia lugar  \n",
       "0       NaN  M329        5.0   6.0  \n",
       "1       NaN  E142        1.0   6.0  \n",
       "2       NaN  E039        1.0   1.0  \n",
       "3       NaN  E149        1.0   6.0  \n",
       "4       NaN  E119        1.0   6.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "column_types = {\n",
    "    'departamento': 'category',\n",
    "    'municipio': 'category',\n",
    "    'sexo': 'category',\n",
    "    'a単o_registrado': 'category', \n",
    "    'edad': 'int64',  \n",
    "    'periodo': 'category',\n",
    "    'etnia': 'category',\n",
    "    'escolaridad': 'category',\n",
    "    'ocupacion': 'category',\n",
    "    'causa': 'category',\n",
    "    'asistencia': 'category',\n",
    "    'lugar': 'category'\n",
    "}\n",
    "\n",
    "defunciones = pd.read_csv('defunciones_clean.csv', dtype=column_types)\n",
    "defunciones.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocessing\n",
    "1. Simplify ICD10 Code\n",
    "2. Use age_groups instead of age\n",
    "3. Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\estra\\AppData\\Local\\Temp\\ipykernel_13156\\277800880.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  defunciones['causa_simplificada'] = defunciones['causa'].apply(lambda x: simplify_icd10(x, code_map))\n",
      "C:\\Users\\estra\\AppData\\Local\\Temp\\ipykernel_13156\\277800880.py:43: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  data['ocupacion'] = data['ocupacion'].replace(['NEOG', 'IGNORADO'], mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de causas antes de simplificar: 3007\n",
      "Numero de causas despues de simplificar: 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>departamento</th>\n",
       "      <th>municipio</th>\n",
       "      <th>sexo</th>\n",
       "      <th>a単o_registrado</th>\n",
       "      <th>periodo</th>\n",
       "      <th>etnia</th>\n",
       "      <th>escolaridad</th>\n",
       "      <th>ocupacion</th>\n",
       "      <th>asistencia</th>\n",
       "      <th>lugar</th>\n",
       "      <th>causa</th>\n",
       "      <th>age_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70905</th>\n",
       "      <td>14.0</td>\n",
       "      <td>1415</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>K00-K95</td>\n",
       "      <td>65+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70906</th>\n",
       "      <td>14.0</td>\n",
       "      <td>1411</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>K00-K95</td>\n",
       "      <td>65+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70907</th>\n",
       "      <td>16.0</td>\n",
       "      <td>1601</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>92</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>K00-K95</td>\n",
       "      <td>65+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70908</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0116</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>K00-K95</td>\n",
       "      <td>65+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70909</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1219</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>K00-K95</td>\n",
       "      <td>65+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      departamento municipio sexo a単o_registrado periodo etnia escolaridad  \\\n",
       "70905         14.0      1415  1.0           2013     3.0   1.0         1.0   \n",
       "70906         14.0      1411  1.0           2013     3.0   1.0         1.0   \n",
       "70907         16.0      1601  1.0           2013     3.0   1.0         9.0   \n",
       "70908          1.0      0116  1.0           2013     3.0   9.0         1.0   \n",
       "70909         12.0      1219  1.0           2013     3.0   4.0         1.0   \n",
       "\n",
       "      ocupacion asistencia lugar    causa age_group  \n",
       "70905        61        5.0   6.0  K00-K95       65+  \n",
       "70906        61        5.0   6.0  K00-K95       65+  \n",
       "70907        92        5.0   6.0  K00-K95       65+  \n",
       "70908        61        5.0   6.0  K00-K95       65+  \n",
       "70909        92        5.0   6.0  K00-K95       65+  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def load_codes(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        codes = json.load(f)\n",
    "    return {entry['code']: entry['code'] for entry in codes if entry['level'] == 0}\n",
    "\n",
    "def simplify_icd10(code, code_map):\n",
    "    if pd.isna(code):\n",
    "        return 'Unknown'\n",
    "    code = code.split('.')[0]  \n",
    "    code_prefix = code[:3]  \n",
    "    for code_range in code_map:\n",
    "        if '-' not in code_range:\n",
    "            if code_range[:3] == code_prefix:\n",
    "                return code_map[code_range]\n",
    "        else: \n",
    "            start, end = code_range.split('-')\n",
    "            start_prefix = start[:3]\n",
    "            end_prefix = end[:3]\n",
    "            \n",
    "            # For example, if the code is 'B014', the prefix is 'B01' and the range is 'B00-B99', so it's a match.\n",
    "            if start_prefix <= code_prefix <= end_prefix:\n",
    "                return code_map[code_range]\n",
    "    return 'Other'\n",
    "\n",
    "def preprocess_data(defunciones, code_map):\n",
    "    defunciones = defunciones.dropna()\n",
    "    defunciones['causa_simplificada'] = defunciones['causa'].apply(lambda x: simplify_icd10(x, code_map))\n",
    "    \n",
    "    print('Numero de causas antes de simplificar:', defunciones['causa'].nunique())\n",
    "    print('Numero de causas despues de simplificar:', defunciones['causa_simplificada'].nunique())\n",
    "    \n",
    "    data = defunciones.copy()\n",
    "    data = data.drop(columns=['causa'])\n",
    "    data = data[data['causa_simplificada'] != 'Other']\n",
    "    data = data.rename(columns={'causa_simplificada': 'causa'})\n",
    "    \n",
    "    mode = data['ocupacion'].mode()[0]\n",
    "    data['ocupacion'] = data['ocupacion'].replace(['NEOG', 'IGNORADO'], mode)\n",
    "    \n",
    "    data['age_group'] = pd.cut(data['edad'], bins=[0, 18, 35, 50, 65, float('inf')],\n",
    "                                        labels=['0-18', '19-35', '36-50', '51-65', '65+'])\n",
    "    \n",
    "    data.drop(columns=['edad'], inplace=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def analyze_causa_counts(simple_causes):\n",
    "    causa_counts = simple_causes['causa'].value_counts()\n",
    "    \n",
    "    plt.boxplot(causa_counts)\n",
    "    plt.show()\n",
    "    \n",
    "    causa_counts_df = simple_causes['causa'].value_counts().reset_index()\n",
    "    causa_counts_df.columns = ['causa', 'count']\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(x='causa', y='count', data=causa_counts_df)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.hist(causa_counts, bins=20)\n",
    "    plt.show()\n",
    "    \n",
    "    causa_counts = causa_counts[causa_counts < 10000]\n",
    "    \n",
    "    return causa_counts\n",
    "  \n",
    "icd10_codes = load_codes('codes.json')\n",
    "causes = preprocess_data(defunciones, icd10_codes)\n",
    "# causa_counts = analyze_causa_counts(causes)\n",
    "# print(causes['age_group'].value_counts())\n",
    "\n",
    "causes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'causes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DecisionTreeClassifier\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Load the dataset\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mcauses\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     16\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39msample(frac\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Separate features and target\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'causes' is not defined"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, pair_confusion_matrix\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Load the dataset\n",
    "data = causes.copy()\n",
    "data = data.sample(frac=0.1, random_state=42)\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('causa', axis=1)\n",
    "X = X.drop('edad', axis=1) # drop the age column, we will use the age_group column\n",
    "y = data['causa']\n",
    "\n",
    "# Apply Random Oversampling\n",
    "X_resampled, y_resampled = RandomOverSampler(random_state=42).fit_resample(X, y)\n",
    "\n",
    "# Use all available features\n",
    "selected_features = X.columns.tolist()\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split( X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the preprocessing pipeline\n",
    "# numeric_features = ['edad']\n",
    "categorical_features = [feat for feat in selected_features if feat != 'edad' ]\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "\n",
    "# # Create the pipeline\n",
    "# pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "#                            ('model',  LogisticRegression(max_iter=1000, C=1, penalty='l2', solver='saga'))])\n",
    "\n",
    "# # Fit the model\n",
    "# pipeline.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions\n",
    "# y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# # Calculate and print the confusion matrix and accuracy\n",
    "# print(\"Confusion Matrix:\")\n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n",
    "# plt.title(f\"Confusion Matrix - Model 1\")\n",
    "# plt.xlabel('Predicted Labels')\n",
    "# plt.ylabel('True Labels')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "    \n",
    "# plt.show()\n",
    "# print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\\n\")\n",
    "\n",
    "pipeline2 = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                            ('model',  DecisionTreeClassifier(random_state=42))])\n",
    "\n",
    "# Fit the model\n",
    "pipeline2.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = pipeline2.predict(X_test)\n",
    "\n",
    "# Calculate and print the confusion matrix and accuracy\n",
    "print(\"Confusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n",
    "plt.title(f\"Confusion Matrix - Model 2\")\n",
    "\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\\n\")\n",
    "\n",
    "# show the tree\n",
    "\n",
    "\n",
    "# parameters = [{'model__C': 1, 'model__l1_ratio': 0.1, 'model__penalty': 'l1', 'model__solver': 'saga'},\n",
    "#               {'model__C': 1.0, 'model__penalty': 'l2'},\n",
    "#               {'model__C': 10.0, 'model__penalty': 'l2'}]\n",
    "\n",
    "# for param in parameters:\n",
    "#     # Set the parameters\n",
    "#     pipeline.set_params(**param)\n",
    "    \n",
    "  \n",
    "\n",
    "# # Define the hyperparameter grid for GridSearchCV\n",
    "# param_grid = {\n",
    "#     'model__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "#     'model__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "#     'model__C': [0.1, 1, 10],\n",
    "#     'model__l1_ratio': [0.1, 0.5, 0.9]\n",
    "# }\n",
    "\n",
    "# # Perform grid search cross-validation\n",
    "# grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Get the best model and accuracy\n",
    "# best_model = grid_search.best_estimator_\n",
    "# best_score = grid_search.best_score_\n",
    "# best_params = grid_search.best_params_\n",
    "\n",
    "# # Make predictions on the test set using the best model\n",
    "# y_pred = best_model.predict(X_test)\n",
    "\n",
    "# # Evaluate the model\n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# print(\"Best Hyperparameters:\", best_params)\n",
    "# print(\"Best Accuracy:\", best_score)\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(cm)\n",
    "# print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Hyperparameters: {'model__C': 1, 'model__l1_ratio': 0.1, 'model__penalty': 'l1', 'model__solver': 'saga'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'causes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomOverSampler\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Carga el conjunto de datos\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mcauses\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     15\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39msample(frac\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Separa caracter鱈sticas y variable objetivo\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'causes' is not defined"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC  # Importa la clase SVC para SVM\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Carga el conjunto de datos\n",
    "data = causes.copy()\n",
    "data = data.sample(frac=0.1, random_state=42)\n",
    "\n",
    "# Separa caracter鱈sticas y variable objetivo\n",
    "X = data.drop('causa', axis=1)\n",
    "X = X.drop('edad', axis=1)  # Elimina la columna de edad, usaremos la columna de grupo de edad\n",
    "y = data['causa']\n",
    "\n",
    "# Aplica Sobremuestreo Aleatorio\n",
    "X_resampled, y_resampled = RandomOverSampler(random_state=42).fit_resample(X, y)\n",
    "\n",
    "# Utiliza todas las caracter鱈sticas disponibles\n",
    "selected_features = X.columns.tolist()\n",
    "\n",
    "# Divide los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crea el preprocesador\n",
    "categorical_features = [feat for feat in selected_features if feat != 'edad']\n",
    "\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Crea el pipeline con SVM\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('model', SVC())])\n",
    "\n",
    "# Define el grid de hiperpar叩metros para GridSearchCV\n",
    "param_grid = {\n",
    "    'model__C': [0.1, 1],\n",
    "    'model__kernel': ['linear', 'rbf'],\n",
    "    'model__gamma': ['scale']\n",
    "}\n",
    "\n",
    "# Realiza la b炭squeda en grid con validaci坦n cruzada\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtiene el mejor modelo y sus par叩metros\n",
    "best_model = grid_search.best_estimator_\n",
    "best_score = grid_search.best_score_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Realiza predicciones en el conjunto de prueba usando el mejor modelo\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Eval炭a el modelo\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Imprime los resultados\n",
    "print(\"Mejores Hiperpar叩metros:\", best_params)\n",
    "print(\"Mejor Precisi坦n:\", best_score)\n",
    "print(\"Matriz de Confusi坦n:\")\n",
    "print(cm)\n",
    "print(\"Precisi坦n en el Conjunto de Prueba:\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
